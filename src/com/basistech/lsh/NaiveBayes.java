package com.basistech.lsh;

import java.util.HashSet;
import java.util.Set;
import org.apache.commons.math.special.Gamma;

/**
 * A naive bayes model for language.  Given a label, each FeatureVector fv is
 * modeled as if it were
 * generated by |vocabulary| poisson processes, each of which runs for a duration
 * equal to |fv|.  We use a conjugate (gamma) prior over each poisson's lambda
 * parameter; the shape
 * of the prior is determined by r_0 and theta_0, where r_0 is the shape parameter
 * and theta_0 is the scale parameter of the gamma.
 * @author cdoersch
 */
public class NaiveBayes implements OnlineLearner {
    private final double theta_0 = 1;
    private final double r_0 = .5;
    private double nPos = 0;
    private double nNeg = 0;
    private DoubleCounter<Integer> negCounts;
    private DoubleCounter<Integer> posCounts;
    private Set<Integer> allKeys;

    public NaiveBayes() {
        posCounts = new DoubleCounter<Integer>();
        negCounts = new DoubleCounter<Integer>();
        //reallocate();
    }

    //private void reallocate() {
        //variance = Arrays.copyOf(variance, maxFeatures * 2);
        //int n = maxFeatures * 2;
        //for (int i = maxFeatures; i < n; ++i) {
        //    variance.put(IntegerCache.get(i),1.0d);
        //}
        //maxFeatures = n;
        //mean = Arrays.copyOf(mean, maxFeatures);
    //}

    @Override
    public void train(FeatureVector feats, int label) {
        for(Integer i: feats.keySet()){
            double val = feats.get(i);
            if(label==1){
                posCounts.increment(i,val);
                nPos+=val;
            }else{
                negCounts.increment(i,val);
                nNeg+=val;
            }
        }
    }

    private double logProbOfFV(FeatureVector fv, double catCount, DoubleCounter<Integer> featCounts){
        double logProb = 0;
        // see http://en.wikipedia.org/wiki/Gamma-Poisson_distribution#Gamma.E2.80.93Poisson_mixture
        // the following formulas give the posterior over each feature count with the poisson process's
        // lambda parameter integrated out.
        double theta=theta_0/(catCount*theta_0+1);
        //double p = theta/(1+theta);
        //for(int i: fv.keySet()){
            //double r=r_0+featCounts.getDouble(i);
            //double k = fv.get(i);
            //note that in the true posterior distribution, "Gamma.logGamma(k+1)" really
            //ought to be replaced by "log(k!)".  For integer k these are the same, but
            //I didn't want the code to break when k is real-valued.
            //logProb += Gamma.logGamma(r+k)-Gamma.logGamma(r)-Gamma.logGamma(k+1);
            //logProb += Math.log(1-p)*r;
            //logProb += Math.log(p)*k;
        //}
        int t = 0;
        for(int i: fv.keySet()){
            t+=fv.get(i);
        }
        for(Integer i: allKeys){
            double r=r_0+featCounts.getDouble(i);
            Double k = fv.get(i);
            if(k==null){k=0.0;}
            logProb+=k*Math.log(t);
            //note that in the true posterior distribution, "Gamma.logGamma(k+1)" really
            //ought to be replaced by "log(k!)".  For integer k these are the same, but
            //I didn't want the code to break when k is real-valued.
            logProb += Gamma.logGamma(r+k)-Gamma.logGamma(r)-Gamma.logGamma(k+1);
            logProb += (k+r)*Math.log(1/(t+1/theta));
            logProb-=r*Math.log(theta);
        }
        return logProb;
    }

    /**
     * In Naive Bayes this method doesn't really make sense.  The contract is that
     * margin>0 implies the positive probability was larger than the negative
     * probability.
     * @param feats
     * @return
     */
    @Override
    public double predictMargin(FeatureVector feats) {
        double posProb = logProbOfFV(feats, nPos, posCounts);
        double negProb = logProbOfFV(feats, nNeg, negCounts);
        return posProb-negProb;
    }

    @Override
    public int predict(FeatureVector feats){
        return predictMargin(feats)>getPositiveThreshold()?1:0;
    }
    
    @Override
    public double getPositiveThreshold() {
        return 0.0d;
    }

    @Override
    public void finish() {
        allKeys=new HashSet<Integer>();
        allKeys.addAll(posCounts.keySet());
        allKeys.addAll(negCounts.keySet());
    }

    @Override
    public String toString() {
        return print(null);
    }

    public String print(Vocabulary vocab){
        StringBuilder str = new StringBuilder();
        for (int i: negCounts.keySet()) {
            str.append(vocab == null ? i : vocab.reverseLookup(i))
                    .append(": posCount=")
                    .append(posCounts.getDouble(i))
                    .append(" negCount=")
                    .append(negCounts.getDouble(i))
                    .append("\n");
        }
        return str.toString();
    }

    @Override
    public String getName() {
        return "nb";
    }
}
